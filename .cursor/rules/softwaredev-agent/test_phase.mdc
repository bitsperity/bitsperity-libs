---
description: 
globs: 
alwaysApply: false
---

# Library-Focused Testing and Validation

## Critical Rules

- **Library-first testing**: All tests must validate actual library functionality, not implementation details or mock behavior
- **Real integration testing**: Test against actual library APIs, not mocked versions
- **Container-based testing**: All tests must run successfully in Docker environment to ensure deployment reliability
- **User scenario validation**: Tests must reflect how real developers will use the library
- **Critical test review**: AI-generated tests require human validation for library correctness
- **Performance validation**: Ensure library meets performance requirements under realistic load conditions

## Library Testing Philosophy

### What to Test (Library-Focused)
```typescript
// âœ… GOOD: Test actual library behavior
describe('LibraryAPI', () => {
  it('should connect to real service and return data', async () => {
    const lib = new MyLibrary();
    const result = await lib.connect('real-endpoint');
    expect(result.status).toBe('connected');
    expect(result.data).toHaveProperty('version');
  });

  it('should handle real network errors gracefully', async () => {
    const lib = new MyLibrary();
    // Test with actual unreachable endpoint
    await expect(lib.connect('unreachable-endpoint')).rejects.toThrow();
  });
});

// âŒ BAD: Testing mocks or implementation details  
describe('LibraryAPI', () => {
  it('should call internal method', () => {
    const mockMethod = jest.fn();
    // This tests the mock, not the library!
  });

  it('should use correct HTTP method', () => {
    // Testing implementation detail, not behavior
  });
});
```

### Library Integration Testing Strategy
```typescript
// âœ… Test library as black box with real dependencies
describe('Library Integration', () => {
  beforeAll(async () => {
    // Setup real test environment, not mocks
    await setupRealTestEnvironment();
  });

  it('complete user workflow works end-to-end', async () => {
    const lib = new MyLibrary();
    
    // Test the actual workflow developers will use
    await lib.initialize();
    const result = await lib.performCoreFunction(realTestData);
    await lib.cleanup();
    
    // Validate actual library behavior
    expect(result).toMatchLibrarySpecification();
  });
});
```

## AI-Generated Test Validation Framework

### Critical Test Review Process
```typescript
// Human review required for all AI-generated tests:

interface TestQualityChecklist {
  // âœ… AI usually handles well
  hasBasicStructure: boolean;     // AI generates good boilerplate
  hasHappyPathCoverage: boolean;  // AI covers basic scenarios
  hasProperAssertions: boolean;   // AI writes valid expect() calls
  
  // âš ï¸ Requires human validation
  testsActualLibrary: boolean;    // NOT implementation details
  usesRealDependencies: boolean;  // NOT excessive mocking
  reflectsUserWorkflow: boolean;  // NOT internal method calls
  hasLibraryEdgeCases: boolean;   // Domain-specific edge cases
  
  // âŒ AI often misses
  hasSecurityTests: boolean;      // Security boundary testing
  hasPerformanceTests: boolean;   // Real performance validation
  hasErrorRecovery: boolean;      // Complex error scenarios
}
```

### Test Review Guidelines
```typescript
// Questions to ask when reviewing AI-generated tests:

const testReviewQuestions = [
  // Library Focus Questions
  "Does this test validate what developers actually care about?",
  "Would this test catch a real bug that affects library users?", 
  "Is this testing library behavior or implementation details?",
  "Does this use real dependencies the library will use in production?",
  
  // User Workflow Questions  
  "Does this reflect how developers will actually use the library?",
  "Are we testing the public API surface, not internal methods?",
  "Do edge cases reflect real-world usage scenarios?",
  
  // Quality Questions
  "Would this test fail if the library breaks in ways users care about?",
  "Are we testing too many mocks instead of actual library functionality?",
  "Do integration tests use real external dependencies when possible?"
];
```

## Library Testing Framework

### 1. Public API Testing (Library Behavior)
```typescript
// Test the actual library API that developers use
describe('Public Library API', () => {
  let library: MyLibrary;
  
  beforeEach(() => {
    // Test with real library instance, minimal mocking
    library = new MyLibrary({
      // Real configuration options
      endpoint: process.env.TEST_ENDPOINT,
      timeout: 5000
    });
  });

  describe('Core Functionality', () => {
    it('performs primary library function correctly', async () => {
      // Test actual library behavior
      const input = createRealTestData();
      const result = await library.coreFunction(input);
      
      // Validate against library specification
      expect(result).toMatchLibraryContract();
      expect(result.success).toBe(true);
    });

    it('handles library-specific error conditions', async () => {
      // Test real error scenarios the library should handle
      const invalidInput = createInvalidTestData();
      
      await expect(library.coreFunction(invalidInput))
        .rejects.toThrow(LibraryError);
    });
  });

  describe('Library Configuration', () => {
    it('respects configuration options', () => {
      const customConfig = { timeout: 1000 };
      const lib = new MyLibrary(customConfig);
      
      // Test that library actually uses configuration
      expect(lib.getTimeout()).toBe(1000);
    });
  });
});
```

### 2. Integration Testing (Real Dependencies)
```typescript
// Test library with real external dependencies
describe('Library Integration', () => {
  describe('External Service Integration', () => {
    it('works with real external service', async () => {
      const library = new MyLibrary();
      
      // Test against real service (test environment)
      const result = await library.connectToService();
      
      // Validate actual integration works
      expect(result.connected).toBe(true);
      expect(result.serviceInfo).toBeDefined();
    });

    it('handles external service failures gracefully', async () => {
      const library = new MyLibrary({
        endpoint: 'http://unreachable-service.test'
      });
      
      // Test real failure scenarios
      await expect(library.connectToService())
        .rejects.toThrow(/Connection failed/);
    });
  });

  describe('File System Integration', () => {
    it('reads and writes actual files', async () => {
      const library = new MyLibrary();
      const testFile = '/tmp/test-file.json';
      
      // Test with real file operations
      await library.writeFile(testFile, { test: 'data' });
      const result = await library.readFile(testFile);
      
      expect(result).toEqual({ test: 'data' });
      
      // Cleanup
      await fs.unlink(testFile);
    });
  });
});
```

### 3. User Workflow Testing (Developer Experience)
```typescript
// Test complete workflows developers will actually use
describe('Developer Workflows', () => {
  describe('Quick Start Workflow', () => {
    it('supports the documented quick start example', async () => {
      // Test exactly what's in the documentation
      const library = new MyLibrary();
      await library.initialize();
      
      const result = await library.quickStart();
      
      expect(result.success).toBe(true);
      expect(result).toHaveProperty('data');
    });
  });

  describe('Advanced Usage Workflow', () => {
    it('supports advanced configuration workflow', async () => {
      const library = new MyLibrary({
        advanced: true,
        customSettings: { feature: 'enabled' }
      });
      
      const result = await library.advancedOperation();
      
      expect(result.features).toContain('advanced');
    });
  });

  describe('Error Recovery Workflow', () => {
    it('allows developers to recover from errors', async () => {
      const library = new MyLibrary();
      
      // Simulate error condition
      await expect(library.operationThatFails()).rejects.toThrow();
      
      // Test recovery workflow
      library.reset();
      const result = await library.operationThatSucceeds();
      
      expect(result.success).toBe(true);
    });
  });
});
```

## Container-Based Testing Execution

### Development Container Tests
```bash
# Run library tests in development container
docker-compose exec app npm run test:library
docker-compose exec app npm run test:integration  
docker-compose exec app npm run test:workflows

# Validate library behavior in containerized environment
docker-compose exec app npm run test:container-specific
```

### Production-Like Testing
```bash
# Test library in production-like container
docker build -f Dockerfile.prod -t library:test .
docker run --rm -e NODE_ENV=test library:test npm run test:production

# Test library installation and usage
docker run --rm library:test npm pack
docker run --rm library:test npm install ./library-*.tgz
```

## Performance Testing (Library-Focused)

### Library Performance Benchmarks
```typescript
describe('Library Performance', () => {
  it('meets performance requirements for typical usage', async () => {
    const library = new MyLibrary();
    const startTime = performance.now();
    
    // Test with realistic data volume
    await library.processTypicalWorkload();
    
    const duration = performance.now() - startTime;
    expect(duration).toBeLessThan(1000); // 1 second max
  });

  it('handles large data sets efficiently', async () => {
    const library = new MyLibrary();
    const largeDataSet = generateLargeTestData(10000);
    
    const result = await library.processLargeData(largeDataSet);
    
    expect(result.processed).toBe(10000);
    expect(result.memory).toBeLessThan(100 * 1024 * 1024); // 100MB max
  });
});
```

## Security Testing (Library-Focused)

### Library Security Validation
```typescript
describe('Library Security', () => {
  it('validates input parameters properly', async () => {
    const library = new MyLibrary();
    
    // Test with malicious input
    const maliciousInput = { 
      script: '<script>alert("xss")</script>',
      sql: "'; DROP TABLE users; --"
    };
    
    await expect(library.processInput(maliciousInput))
      .rejects.toThrow(/Invalid input/);
  });

  it('handles sensitive data securely', async () => {
    const library = new MyLibrary();
    const sensitiveData = { password: 'secret123' };
    
    const result = await library.processSensitiveData(sensitiveData);
    
    // Ensure sensitive data is not exposed
    expect(JSON.stringify(result)).not.toContain('secret123');
  });
});
```

## Test Quality Validation Process

### Automated Test Review
```typescript
// Automated checks for test quality
const validateTestSuite = (testFiles: string[]) => {
  const issues = [];
  
  testFiles.forEach(file => {
    const content = readFileSync(file, 'utf8');
    
    // Check for mock overuse (indicates testing implementation, not behavior)
    const mockCount = (content.match(/jest\.mock|mockReturnValue/g) || []).length;
    const testCount = (content.match(/it\(/g) || []).length;
    
    if (mockCount > testCount * 0.3) {
      issues.push(`${file}: Too many mocks (${mockCount}/${testCount})`);
    }
    
    // Check for library API usage
    if (!content.includes('new MyLibrary(')) {
      issues.push(`${file}: Not testing actual library instantiation`);
    }
    
    // Check for real assertions
    if (!content.includes('expect(') || content.includes('expect(mock')) {
      issues.push(`${file}: Testing mocks instead of library behavior`);
    }
  });
  
  return issues;
};
```

### Manual Review Checklist
```markdown
## Test Review Checklist

### Library Focus âœ…
- [ ] Tests instantiate actual library classes
- [ ] Tests call public API methods, not internal functions  
- [ ] Tests validate library behavior, not implementation details
- [ ] Integration tests use real dependencies when possible
- [ ] Tests reflect documented usage patterns

### User Workflow âœ…
- [ ] Tests match documentation examples
- [ ] Tests cover complete user workflows
- [ ] Error handling tests reflect real error scenarios
- [ ] Performance tests use realistic data volumes
- [ ] Tests validate developer experience expectations

### Quality Assurance âœ…
- [ ] Tests would fail if library behavior changes
- [ ] Minimal mocking (only for external services)
- [ ] Tests run against containerized library
- [ ] Tests validate security boundaries
- [ ] Tests cover edge cases specific to library domain
```

## Testing Execution Strategy

### Week 1: Core Library Testing (Days 1-7)

**Days 1-3: Public API Validation**
- Review all AI-generated tests for library focus
- Ensure tests validate actual library behavior
- Add missing user workflow tests
- Remove tests that only validate mocks

**Days 4-5: Integration Testing**
- Test library with real external dependencies
- Validate container-based library operation
- Test installation and usage workflows

**Days 6-7: Performance & Security**
- Performance testing with realistic data
- Security testing with actual threat scenarios
- Memory and resource usage validation

### Week 2: Quality Assurance (Days 8-14)

**Days 8-10: User Experience Testing**
- Test documentation examples work correctly
- Validate developer onboarding workflows
- Test error messages and debugging experience

**Days 11-12: Production Readiness**
- Test library in production-like containers
- Validate packaging and distribution
- Test with different Node.js versions

**Days 13-14: Final Validation**
- Comprehensive library behavior validation
- Performance benchmarking
- Security scan and validation

## Quality Validation

### Testing Completeness Check
- âœ… **Library behavior validated**: Tests focus on actual library functionality
- âœ… **User workflows tested**: Tests reflect real developer usage
- âœ… **Minimal mocking**: Tests use real dependencies where possible
- âœ… **Container validation**: All tests pass in Docker environment
- âœ… **Performance validated**: Library meets performance requirements
- âœ… **Security cleared**: No critical security vulnerabilities found
- âœ… **Documentation tested**: All examples work correctly

### Library-Specific Validation
- âœ… **API completeness**: All public APIs have behavior tests
- âœ… **Error handling**: Real error scenarios tested
- âœ… **Configuration**: Library options properly tested
- âœ… **Integration**: External dependencies tested with real services
- âœ… **Installation**: Package installation workflow validated

## Termination Criteria

The test_phase rule terminates when:

1. **Library behavior validated**: All tests focus on actual library functionality, not mocks
2. **User workflows tested**: Complete developer usage scenarios validated
3. **Container testing complete**: All tests pass in production-like containers
4. **Performance benchmarks met**: Library meets performance requirements
5. **Security validation passed**: No critical vulnerabilities in library
6. **Documentation accuracy verified**: All examples and workflows tested

## Enhanced Handoff Message

Upon successful completion, provide this standardized message:

```
ðŸ§ª Library Testing Complete - Real Functionality Validated

ðŸ“Š Testing Summary:
- Library API Tests: âœ… {X} tests validating actual library behavior
- User Workflow Tests: âœ… {Y} complete developer scenarios tested  
- Integration Tests: âœ… Real dependencies tested (minimal mocking)
- Performance: âœ… Library meets benchmarks under realistic load
- Security: âœ… Library boundaries properly secured
- Container Validation: âœ… All tests pass in production containers

ðŸŽ¯ Quality Validation:
- Mock Usage: {X}% (target: <30% of tests)
- Library Coverage: {Y}% of public API tested
- Workflow Coverage: {Z} complete user scenarios validated
- Real Integration: {A}% of external dependencies tested without mocks

âš ï¸ Test Review Results:
- AI-Generated Tests Reviewed: âœ… {B} tests validated for library focus
- Implementation Detail Tests Removed: âœ… {C} tests refactored
- User Workflow Tests Added: âœ… {D} missing scenarios covered

ðŸ“ Test Artifacts:
- Library behavior test reports  
- User workflow validation results
- Performance benchmark data
- Security validation reports
- Container test execution logs

ðŸ”„ Next: finalize_phase.mdc will create retrospective and prepare handoff

Library functionality properly tested? [âœ… Yes]
User workflows validated? [âœ… Yes] 
Minimal mocking confirmed? [âœ… Yes]
Ready for phase finalization? [Yes/No]
```

## Testing Philosophy

- **Library-First**: Test what developers actually use, not internal implementation
- **Real-World Focus**: Use actual dependencies and realistic scenarios
- **User-Centric**: Validate complete workflows developers will perform
- **Quality-Driven**: Ensure tests catch real bugs that affect library users
- **Container-Validated**: All testing in production-like environments
- **AI-Assisted but Human-Validated**: Leverage AI for test generation, require human review for quality

Remember: The goal is not just test coverage, but ensuring the library actually works correctly for real developers in real scenarios. Tests should validate library behavior, not implementation details.

## Agent Chain Commands

Upon successful completion, execute:
```bash
# Deactivate current rule and activate next
sed -i 's/alwaysApply: true/alwaysApply: false/' .cursor/rules/softwaredev-agent/test_phase.mdc && sed -i 's/alwaysApply: false/alwaysApply: true/' .cursor/rules/softwaredev-agent/finalize_phase.mdc
```
